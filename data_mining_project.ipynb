{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Data Mining Project\n",
    "\n",
    "This notebook is designed to work in Google Colab for data mining tasks.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FarnoodTavasoli/datamining_project/blob/main/data_mining_project.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Colab\n",
    "\n",
    "This section sets up the environment when running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running on Google Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Mount Google Drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted successfully!\")\n",
    "else:\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "\n",
    "Loading the Ionosphere dataset and performing initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ionosphere dataset\n",
    "if IN_COLAB:\n",
    "    # Update this path to point to your uploaded files folder in Google Drive\n",
    "    data_path = '/content/drive/MyDrive/datamining_project/ionosphere.data'\n",
    "else:\n",
    "    # Local path\n",
    "    data_path = 'files/ionosphere_5/ionosphere.data'\n",
    "\n",
    "# Column names for the dataset\n",
    "# 34 continuous features + 1 target variable\n",
    "column_names = [f'feature_{i}' for i in range(1, 35)] + ['class']\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_path, header=None, names=column_names)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNumber of instances: {df.shape[0]}\")\n",
    "print(f\"Number of features: {df.shape[1] - 1}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['class'].value_counts())\n",
    "print(f\"\\nClass proportions:\")\n",
    "print(df['class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"Statistical Summary of Features:\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "df['class'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "df['class'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
    "                                colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
    "axes[1].set_title('Class Proportion', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions (all 34 features)\n",
    "num_features = 34\n",
    "n_cols = 6\n",
    "n_rows = int(np.ceil(num_features / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 3))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(num_features):\n",
    "    feature_name = f'feature_{i+1}'\n",
    "    axes[i].hist(df[feature_name], bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    axes[i].set_title(f'{feature_name}', fontsize=9)\n",
    "    axes[i].set_xlabel('Value', fontsize=8)\n",
    "    axes[i].set_ylabel('Frequency', fontsize=8)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for j in range(num_features, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle('Distribution of All 34 Features', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (all 34 features)\n",
    "plt.figure(figsize=(18, 14))\n",
    "correlation_matrix = df.iloc[:, :34].corr()\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0,\n",
    "            linewidths=0.3, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Correlation Heatmap (All 34 Features)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Preparing the data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Encode target variable (g=good, b=bad)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y_encoded.shape}\")\n",
    "print(f\"\\nClass encoding:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {class_name} -> {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(f\"\\nScaled training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test data shape: {X_test_scaled.shape}\")\n",
    "print(f\"\\nSample scaled features (first 5):\")\n",
    "print(X_train_scaled[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "### Customization Parameter: d = 2\n",
    "\n",
    "We'll train multiple classifiers with customization parameter d=2 where applicable:\n",
    "- **K-Nearest Neighbors (KNN)**: Using k=2 neighbors\n",
    "- **Decision Tree**: With max_depth=2\n",
    "- **Support Vector Machine (SVM)**: With degree=2 polynomial kernel\n",
    "- **Neural Network (MLP)**: With 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customization parameter\n",
    "d = 2\n",
    "print(f\"Customization parameter d = {d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. K-Nearest Neighbors (KNN) with k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN with k=d\n",
    "knn_model = KNeighborsClassifier(n_neighbors=d)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "knn_precision = precision_score(y_test, y_pred_knn)\n",
    "knn_recall = recall_score(y_test, y_pred_knn)\n",
    "knn_f1 = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"KNN (k={d}) Performance:\")\n",
    "print(f\"  Accuracy:  {knn_accuracy:.4f}\")\n",
    "print(f\"  Precision: {knn_precision:.4f}\")\n",
    "print(f\"  Recall:    {knn_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {knn_f1:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree with max_depth=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Tree with max_depth=d\n",
    "dt_model = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "dt_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "dt_recall = recall_score(y_test, y_pred_dt)\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "print(f\"Decision Tree (max_depth={d}) Performance:\")\n",
    "print(f\"  Accuracy:  {dt_accuracy:.4f}\")\n",
    "print(f\"  Precision: {dt_precision:.4f}\")\n",
    "print(f\"  Recall:    {dt_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {dt_f1:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Support Vector Machine (SVM) with polynomial degree=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM with polynomial kernel degree=d\n",
    "svm_model = SVC(kernel='poly', degree=d, random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "svm_precision = precision_score(y_test, y_pred_svm)\n",
    "svm_recall = recall_score(y_test, y_pred_svm)\n",
    "svm_f1 = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"SVM (polynomial degree={d}) Performance:\")\n",
    "print(f\"  Accuracy:  {svm_accuracy:.4f}\")\n",
    "print(f\"  Precision: {svm_precision:.4f}\")\n",
    "print(f\"  Recall:    {svm_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {svm_f1:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multi-Layer Perceptron (MLP) with 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP with d hidden layers\n",
    "# Using (100, 50) neurons for 2 hidden layers\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_mlp = mlp_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "mlp_precision = precision_score(y_test, y_pred_mlp)\n",
    "mlp_recall = recall_score(y_test, y_pred_mlp)\n",
    "mlp_f1 = f1_score(y_test, y_pred_mlp)\n",
    "\n",
    "print(f\"MLP ({d} hidden layers) Performance:\")\n",
    "print(f\"  Accuracy:  {mlp_accuracy:.4f}\")\n",
    "print(f\"  Precision: {mlp_precision:.4f}\")\n",
    "print(f\"  Recall:    {mlp_recall:.4f}\")\n",
    "print(f\"  F1-Score:  {mlp_f1:.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_mlp, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile results\n",
    "results = {\n",
    "    'Model': ['KNN (k=2)', 'Decision Tree (depth=2)', 'SVM (poly deg=2)', 'MLP (2 layers)'],\n",
    "    'Accuracy': [knn_accuracy, dt_accuracy, svm_accuracy, mlp_accuracy],\n",
    "    'Precision': [knn_precision, dt_precision, svm_precision, mlp_precision],\n",
    "    'Recall': [knn_recall, dt_recall, svm_recall, mlp_recall],\n",
    "    'F1-Score': [knn_f1, dt_f1, svm_f1, mlp_f1]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "\n",
    "for idx, (ax, metric) in enumerate(zip(axes.ravel(), metrics)):\n",
    "    bars = ax.bar(results_df['Model'], results_df[metric], color=colors[idx], alpha=0.8, edgecolor='black')\n",
    "    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(metric, fontsize=12)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Model Performance Comparison (d={d})', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar chart for comprehensive comparison\n",
    "from math import pi\n",
    "\n",
    "categories = metrics\n",
    "N = len(categories)\n",
    "\n",
    "# Create angles for each metric\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# Plot each model\n",
    "model_colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
    "for i, model in enumerate(results_df['Model']):\n",
    "    values = results_df.iloc[i, 1:].values.tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=model, color=model_colors[i])\n",
    "    ax.fill(angles, values, alpha=0.15, color=model_colors[i])\n",
    "\n",
    "# Fix axis to go in the right order\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, size=12)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], size=10)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.title(f'Model Performance Radar Chart (d={d})', size=16, fontweight='bold', pad=20)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "models_predictions = [\n",
    "    ('KNN (k=2)', y_pred_knn),\n",
    "    ('Decision Tree (depth=2)', y_pred_dt),\n",
    "    ('SVM (poly deg=2)', y_pred_svm),\n",
    "    ('MLP (2 layers)', y_pred_mlp)\n",
    "]\n",
    "\n",
    "for ax, (model_name, y_pred) in zip(axes.ravel(), models_predictions):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "                xticklabels=label_encoder.classes_, \n",
    "                yticklabels=label_encoder.classes_,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    ax.set_title(f'Confusion Matrix - {model_name}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('True Label', fontsize=11)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=11)\n",
    "\n",
    "plt.suptitle(f'Confusion Matrices for All Models (d={d})', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best model\n",
    "best_model_idx = results_df['Accuracy'].idxmax()\n",
    "best_model = results_df.iloc[best_model_idx]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BEST PERFORMING MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {best_model['Model']}\")\n",
    "print(f\"Accuracy:  {best_model['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {best_model['Precision']:.4f}\")\n",
    "print(f\"Recall:    {best_model['Recall']:.4f}\")\n",
    "print(f\"F1-Score:  {best_model['F1-Score']:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation Analysis\n",
    "\n",
    "Perform k-fold cross-validation to assess model stability and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation for all models\n",
    "models = [\n",
    "    ('KNN (k=2)', knn_model),\n",
    "    ('Decision Tree (depth=2)', dt_model),\n",
    "    ('SVM (poly deg=2)', svm_model),\n",
    "    ('MLP (2 layers)', mlp_model)\n",
    "]\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "print(\"Cross-Validation Results (5-fold):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_name, model in models:\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    cv_results.append({\n",
    "        'Model': model_name,\n",
    "        'Mean CV Score': scores.mean(),\n",
    "        'Std CV Score': scores.std(),\n",
    "        'Min Score': scores.min(),\n",
    "        'Max Score': scores.max()\n",
    "    })\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Mean Accuracy: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    print(f\"  Individual Fold Scores: {[f'{s:.4f}' for s in scores]}\")\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nSummary:\")\n",
    "print(cv_results_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validation results\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x_pos = np.arange(len(cv_results_df))\n",
    "means = cv_results_df['Mean CV Score']\n",
    "stds = cv_results_df['Std CV Score']\n",
    "\n",
    "bars = ax.bar(x_pos, means, yerr=stds, capsize=5, alpha=0.8, \n",
    "              color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'], \n",
    "              edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Cross-Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title(f'5-Fold Cross-Validation Results (d={d})', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(cv_results_df['Model'], rotation=45, ha='right')\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, mean, std) in enumerate(zip(bars, means, stds)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
    "            f'{mean:.3f}\\nÂ±{std:.3f}',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This data mining project analyzed the **Ionosphere dataset** using four different classification algorithms with customization parameter **d=2**:\n",
    "\n",
    "1. **K-Nearest Neighbors (KNN)** with k=2 neighbors\n",
    "2. **Decision Tree** with max_depth=2\n",
    "3. **Support Vector Machine (SVM)** with polynomial kernel degree=2\n",
    "4. **Multi-Layer Perceptron (MLP)** with 2 hidden layers\n",
    "\n",
    "### Key Findings:\n",
    "- The dataset contains 351 instances with 34 continuous features\n",
    "- Binary classification: \"good\" vs \"bad\" radar returns\n",
    "- All models were evaluated using accuracy, precision, recall, and F1-score\n",
    "- Cross-validation confirmed model stability and generalization capability\n",
    "\n",
    "### Recommendations:\n",
    "- The best-performing model (based on test accuracy) can be used for production\n",
    "- Consider experimenting with different values of d to optimize performance\n",
    "- Feature engineering and selection could further improve results\n",
    "- Ensemble methods could be explored for better performance"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
