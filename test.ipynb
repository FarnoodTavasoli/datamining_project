{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dc488aa",
   "metadata": {},
   "source": [
    "# Data Mining Project\n",
    "\n",
    "This notebook is designed to work in Google Colab for data mining tasks.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FarnoodTavasoli/datamining_project/blob/main/data_mining_project.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21830834",
   "metadata": {},
   "source": [
    "## Setup for Google Colab\n",
    "\n",
    "This section sets up the environment when running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    drive.mount('/content/drive',force_remount=True)\n",
    "    print(\"Google Drive mounted successfully!\")\n",
    "else:\n",
    "    print(\"Running locally\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288d1bd6",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration\n",
    "\n",
    "Loading the Ionosphere dataset and performing initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ionosphere dataset\n",
    "if IN_COLAB:\n",
    "    data_path = '/content/drive/MyDrive/datamining_project/ionosphere.data'\n",
    "else:\n",
    "    data_path = 'files/ionosphere_5/ionosphere.data'\n",
    "\n",
    "\n",
    "column_names = [f'feature_{i}' for i in range(1, 35)] + ['class']\n",
    "\n",
    "df = pd.read_csv(data_path, header=None, names=column_names)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic dataset info\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\Rows: {df.shape[0]}\")\n",
    "print(f\"Features: {df.shape[1] - 1}\")\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7601985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "df['class'].value_counts().plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Class Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "df['class'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', \n",
    "                                colors=['#2ecc71', '#e74c3c'], startangle=90)\n",
    "axes[1].set_title('Class Proportion', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f959a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "num_features = 34\n",
    "n_cols = 6\n",
    "n_rows = int(np.ceil(num_features / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 3))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(num_features):\n",
    "    feature_name = f'feature_{i+1}'\n",
    "    axes[i].hist(df[feature_name], bins=30, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    axes[i].set_title(f'{feature_name}', fontsize=9)\n",
    "    axes[i].set_xlabel('Value', fontsize=8)\n",
    "    axes[i].set_ylabel('Frequency', fontsize=8)\n",
    "\n",
    "# Hide unused subplots\n",
    "for j in range(num_features, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle('Distribution of Features', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(18, 14))\n",
    "correlation_matrix = df.iloc[:, :34].corr()\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0,\n",
    "            linewidths=0.3, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Correlation Heatmap', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f3b4b",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Preparing the data for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Encode target variable (g=good, b=bad)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"\\nClass encoding:\")\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {class_name} -> {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0be30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove constant features (columns with no variety)\n",
    "# Identify features where all non-null values are identical\n",
    "constant_features = []\n",
    "for column in X.columns:\n",
    "    if X[column].nunique() == 1:\n",
    "        constant_features.append(column)\n",
    "\n",
    "# Drop constant features\n",
    "if constant_features:\n",
    "    print(f\"Found {len(constant_features)} constant feature(s) with no variety:\")\n",
    "    for feature in constant_features:\n",
    "        print(f\"  - {feature}: {X[feature].unique()[0]}\")\n",
    "    \n",
    "    X = X.drop(columns=constant_features)\n",
    "    print(f\"\\nConstant features dropped!\")\n",
    "    print(f\"Features shape after removing constant features: {X.shape}\")\n",
    "else:\n",
    "    print(\"No constant features found. All features have variety.\")\n",
    "\n",
    "print(f\"\\nRemaining features shape: {X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e9471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling (standardization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(f\"\\nScaled training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test data shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0058c6",
   "metadata": {},
   "source": [
    "## Preprocessing Results Visualization\n",
    "\n",
    "Visualizing how the data has changed after preprocessing and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6375cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs scaled features statistics - ALL DATA\n",
    "comparison_stats = pd.DataFrame({\n",
    "    'Feature': [f'F{i+1}' for i in range(X_train.shape[1])],\n",
    "    'Original Mean': X_train.mean().values,\n",
    "    'Original Std': X_train.std().values,\n",
    "    'Scaled Mean': X_train_scaled.mean(axis=0),\n",
    "    'Scaled Std': X_train_scaled.std(axis=0)\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DATA STATISTICS: ORIGINAL vs SCALED (All Features)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_stats.round(4).to_string(index=False))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Statistics of scaled data\n",
    "print(\"=\"*80)\n",
    "print(\"SCALED TRAINING DATA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Overall Mean (should be ~0): {X_train_scaled.mean():.6f}\")\n",
    "print(f\"Overall Std Dev (should be ~1): {X_train_scaled.std():.6f}\")\n",
    "print(f\"Min value: {X_train_scaled.min():.4f}\")\n",
    "print(f\"Max value: {X_train_scaled.max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827fabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary table\n",
    "print(\"=\"*80)\n",
    "print(\"DATA PREPROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Samples',\n",
    "        'Training Samples',\n",
    "        'Test Samples',\n",
    "        'Number of Features',\n",
    "        'Class 0 (Bad)',\n",
    "        'Class 1 (Good)',\n",
    "        'Feature Scaling',\n",
    "        'Scaled Data Mean',\n",
    "        'Scaled Data Std Dev'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{len(df)}\",\n",
    "        f\"{len(X_train)}\",\n",
    "        f\"{len(X_test)}\",\n",
    "        f\"{X_train.shape[1]}\",\n",
    "        f\"{(y_train == 0).sum()}\",\n",
    "        f\"{(y_train == 1).sum()}\",\n",
    "        \"StandardScaler\",\n",
    "        f\"{X_train_scaled.mean():.6f}\",\n",
    "        f\"{X_train_scaled.std():.6f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4528878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Split proportions\n",
    "split_labels = ['Train Set', 'Test Set']\n",
    "split_sizes = [len(X_train), len(X_test)]\n",
    "colors_split = ['#3498db', '#e74c3c']\n",
    "\n",
    "axes[0].bar(split_labels, split_sizes, color=colors_split, edgecolor='black', linewidth=2)\n",
    "axes[0].set_title('Train/Test Split Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=11)\n",
    "for i, v in enumerate(split_sizes):\n",
    "    axes[0].text(i, v + 5, str(v), ha='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "# Class distribution in train and test sets\n",
    "train_class_dist = pd.Series(y_train).value_counts().sort_index()\n",
    "test_class_dist = pd.Series(y_test).value_counts().sort_index()\n",
    "class_names = ['Bad (0)', 'Good (1)']\n",
    "\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[1].bar(x - width/2, train_class_dist.values, width, label='Train Set', color='#3498db', edgecolor='black')\n",
    "axes[1].bar(x + width/2, test_class_dist.values, width, label='Test Set', color='#e74c3c', edgecolor='black')\n",
    "axes[1].set_title('Class Distribution in Train/Test Sets', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Number of Samples', fontsize=11)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(class_names)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize boxplots comparing original vs scaled data - ALL FEATURES\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Original data boxplot\n",
    "num_features = X_train.shape[1]\n",
    "axes[0].boxplot([X_train.iloc[:, i] for i in range(num_features)], labels=[f'F{i+1}' for i in range(num_features)])\n",
    "axes[0].set_title(f'Original Features Boxplot (All {num_features} Features)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].set_xlabel('Features')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Scaled data boxplot\n",
    "axes[1].boxplot([X_train_scaled[:, i] for i in range(num_features)], labels=[f'F{i+1}' for i in range(num_features)])\n",
    "axes[1].set_title(f'Scaled Features Boxplot (All {num_features} Features)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_xlabel('Features')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ALL feature distributions - original vs scaled\n",
    "num_features = X_train.shape[1]\n",
    "# Calculate subplot grid: one per feature\n",
    "num_cols = 4\n",
    "num_rows = (num_features + num_cols - 1) // num_cols\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, 4*num_rows))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(num_features):\n",
    "    # Plot original\n",
    "    axes[i].hist(X_train.iloc[:, i], bins=30, alpha=0.6, label='Original', color='steelblue', edgecolor='black')\n",
    "    # Plot scaled on secondary axis\n",
    "    ax2 = axes[i].twinx()\n",
    "    ax2.hist(X_train_scaled[:, i], bins=30, alpha=0.6, label='Scaled', color='orange', edgecolor='black')\n",
    "    \n",
    "    axes[i].set_title(f'Feature {i+1}', fontsize=10, fontweight='bold')\n",
    "    axes[i].set_xlabel('Value', fontsize=9)\n",
    "    axes[i].set_ylabel('Frequency (Original)', color='steelblue', fontsize=9)\n",
    "    ax2.set_ylabel('Frequency (Scaled)', color='orange', fontsize=9)\n",
    "    axes[i].tick_params(axis='y', labelcolor='steelblue')\n",
    "    ax2.tick_params(axis='y', labelcolor='orange')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(num_features, len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f'All {num_features} Features: Original vs Scaled Distributions', fontsize=14, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fab2e12",
   "metadata": {},
   "source": [
    "## Cross Validation effect on Decision Tree\n",
    "\n",
    "Compare four Decision Tree training strategies and evaluate them on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20177a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to evaluate a model on the test set\n",
    "# TPR = Recall, FPR = FP / (FP + TN)\n",
    "def evaluate_on_test(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall (TPR)': tpr,\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'FPR': fpr\n",
    "    }\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"DECISION TREE: 4 TRAINING STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1) Normal training (no CV, no pruning)\n",
    "base_tree = DecisionTreeClassifier(random_state=42)\n",
    "base_tree.fit(X_train, y_train)\n",
    "\n",
    "# 2) Normal training with 10-fold CV (no pruning)\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(DecisionTreeClassifier(random_state=42), X_train, y_train, cv=cv, scoring='accuracy')\n",
    "cv_tree = DecisionTreeClassifier(random_state=42)\n",
    "cv_tree.fit(X_train, y_train)\n",
    "\n",
    "# 3) Normal training with CCP post-pruning (alpha chosen by simple validation on train)\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "path = DecisionTreeClassifier(random_state=42).cost_complexity_pruning_path(X_train_sub, y_train_sub)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "val_scores = []\n",
    "for alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
    "    clf.fit(X_train_sub, y_train_sub)\n",
    "    val_scores.append(accuracy_score(y_val, clf.predict(X_val)))\n",
    "\n",
    "best_alpha_val = ccp_alphas[int(np.argmax(val_scores))]\n",
    "ccp_tree = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha_val)\n",
    "ccp_tree.fit(X_train, y_train)\n",
    "\n",
    "# 4) 10-fold CV with CCP (alpha chosen by CV on train)\n",
    "cv_alpha_scores = []\n",
    "for alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=alpha)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    cv_alpha_scores.append(scores.mean())\n",
    "\n",
    "best_alpha_cv = ccp_alphas[int(np.argmax(cv_alpha_scores))]\n",
    "ccp_cv_tree = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha_cv)\n",
    "ccp_cv_tree.fit(X_train, y_train)\n",
    "\n",
    "# Compare all models on test set\n",
    "results = []\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Normal Training',\n",
    "    'CV Accuracy (train)': None,\n",
    "    'CCP Alpha': None,\n",
    "    **evaluate_on_test(base_tree, X_test, y_test)\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Model': '10-Fold CV Training',\n",
    "    'CV Accuracy (train)': cv_scores.mean(),\n",
    "    'CCP Alpha': None,\n",
    "    **evaluate_on_test(cv_tree, X_test, y_test)\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Normal + CCP Pruning',\n",
    "    'CV Accuracy (train)': None,\n",
    "    'CCP Alpha': best_alpha_val,\n",
    "    **evaluate_on_test(ccp_tree, X_test, y_test)\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Model': '10-Fold CV + CCP',\n",
    "    'CV Accuracy (train)': max(cv_alpha_scores),\n",
    "    'CCP Alpha': best_alpha_cv,\n",
    "    **evaluate_on_test(ccp_cv_tree, X_test, y_test)\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Nice formatting\n",
    "results_df['CV Accuracy (train)'] = results_df['CV Accuracy (train)'].round(4)\n",
    "results_df['CCP Alpha'] = results_df['CCP Alpha'].apply(lambda x: None if x is None else round(float(x), 6))\n",
    "for col in ['Accuracy', 'Precision', 'Recall (TPR)', 'F1', 'FPR']:\n",
    "    results_df[col] = results_df[col].round(4)\n",
    "\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Highlight best model by test accuracy\n",
    "best_model = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "print(\"\\nBest model by test accuracy:\")\n",
    "print(best_model.to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
